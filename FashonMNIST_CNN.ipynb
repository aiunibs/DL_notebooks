{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN visualisation with Tensorboard on FashonMNIS\n",
        "written by [Mattia Chiari](mailto:m.chiari017@unibs.it)\n"
      ],
      "metadata": {
        "id": "87uhzmtPSn9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sources \n",
        "* https://www.kaggle.com/code/rutvikdeshpande/fashion-mnist-cnn-beginner-98/notebook\n",
        "* https://en.wikipedia.org/wiki/LeNet\n",
        "* https://www.kaggle.com/code/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist/notebook"
      ],
      "metadata": {
        "id": "4tfAaoMkzYB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "ObFRHRFggEVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "_TpIQTbHye21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n"
      ],
      "metadata": {
        "id": "43mPwMbf4Pk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: FashonMNIST\n",
        "\n",
        "You can find more information about the dataset [here](https://github.com/zalandoresearch/fashion-mnist)"
      ],
      "metadata": {
        "id": "vFCR5tVTgXaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants"
      ],
      "metadata": {
        "id": "w99h38pVga-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FashonMNIST labels values\n",
        "class_names = {-1: '',\n",
        "               0:\t'T-shirt/top',\n",
        "               1:\t'Trouser',\n",
        "               2:\t'Pullover',\n",
        "               3:\t'Dress',\n",
        "               4:\t'Coat',\n",
        "               5:\t'Sandal',\n",
        "               6:\t'Shirt',\n",
        "               7:\t'Sneaker',\n",
        "               8:\t'Bag',\n",
        "               9:\t'Ankle boot'}"
      ],
      "metadata": {
        "id": "y_1o8N7OzJ_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom functions"
      ],
      "metadata": {
        "id": "IXTtDh8Cgeif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4nbW5xJyXrF"
      },
      "outputs": [],
      "source": [
        "def image_grid(x: list, y: list, figures: int = 36, cols: int = 6):\n",
        "    \"\"\"\n",
        "    Plot a grid of images\n",
        "\n",
        "    Args:\n",
        "        x (list): list of images\n",
        "        y (list): list of labels as integers\n",
        "        figures (int, optional): number of figures to plot. Defaults to 36.\n",
        "        cols (int, optional): number of columns in the grid. Defaults to 6.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: if x and y have different lengths\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: a figure with a grid of images\n",
        "    \"\"\"\n",
        "    if len(x) != len(y):\n",
        "        raise ValueError(\"x and y must have the same length\")\n",
        "\n",
        "    figure = plt.figure(figsize=(12,12))\n",
        "\n",
        "    lines = np.ceil(float(figures)/cols)\n",
        "    for i in range(figures):\n",
        "        plt.subplot(lines, cols, i + 1)\n",
        "        plt.xlabel(class_names[y[i]])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(x[i], cmap=plt.cm.coolwarm)\n",
        "        #plt.tight_layout()\n",
        "\n",
        "    return figure"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "mzd1hyExglBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download FashonMNIST\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "vrzKT-egyfxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the images\n",
        "x_train_scaled, x_test_scaled = x_train/255.0, x_test/255.0"
      ],
      "metadata": {
        "id": "ua-XSvAdyaC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure_train = image_grid(x_train, y_train)"
      ],
      "metadata": {
        "id": "JdTDZYr8zFGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run TensorBoard"
      ],
      "metadata": {
        "id": "UaWvJzWTgspB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom functions"
      ],
      "metadata": {
        "id": "ACPL7ktKg282"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  \"\"\"\n",
        "  Create a simple functional model\n",
        "\n",
        "  Returns:\n",
        "      Model: a simple model \n",
        "  \"\"\"\n",
        "  input_layer = tf.keras.layers.Input(shape=(28,28,1), name='input')\n",
        "  conv1_layer = tf.keras.layers.Conv2D(16, (3,3), activation='relu', name='conv1')(input_layer)\n",
        "  dropout1_layer = tf.keras.layers.Dropout(0.2)(conv1_layer)\n",
        "  maxpool1_layer = tf.keras.layers.MaxPool2D((2,2))(dropout1_layer)\n",
        "  conv3_layer = tf.keras.layers.Conv2D(64, (3,3), activation='relu', name='conv3')(maxpool2_layer)\n",
        "  dropout3_layer = tf.keras.layers.Dropout(0.2)(conv3_layer)\n",
        "  maxpool3_layer = tf.keras.layers.MaxPool2D((2,2))(dropout3_layer)\n",
        "  flatten_layer = tf.keras.layers.Flatten()(maxpool3_layer)\n",
        "  dense_layer = tf.keras.layers.Dense(64, activation='relu')(flatten_layer)\n",
        "  output_layer = tf.keras.layers.Dense(10, activation='softmax')(dense_layer)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=[input_layer], outputs=[output_layer])\n",
        "  return model"
      ],
      "metadata": {
        "id": "XyifsAk-zNmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_to_image(figure: plt.figure):\n",
        "    \"\"\"\n",
        "    Convert a matplotlib figure to a tensor\n",
        "\n",
        "    Args:\n",
        "        figure (plt.figure): a matplotlib figure\n",
        "\n",
        "    Returns:\n",
        "        tensor: a tensor that contains the image\n",
        "    \"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "\n",
        "    digit = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    digit = tf.expand_dims(digit, 0)\n",
        "\n",
        "    return digit"
      ],
      "metadata": {
        "id": "K7D0mwFeAJce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_log_images(submodels: list, input_img:np.ndarray, file_writer_img: tf.summary.SummaryWriter):\n",
        "    \"\"\"\n",
        "    Create a callback that will plot a intermediate images\n",
        "\n",
        "    Args:\n",
        "        submodels(list): a list of submodels\n",
        "        input_img: input image\n",
        "        file_writer_img (tf.summary.SummaryWriter): a file writer\n",
        "    \"\"\"\n",
        "\n",
        "    def log_intermediate_images(epoch: int, logs: dict):\n",
        "        \"\"\"\n",
        "        Log intermediate images\n",
        "\n",
        "        Args:\n",
        "            epoch (int): current epoch\n",
        "            logs (dict): logs\n",
        "        \"\"\"\n",
        "        preds = []\n",
        "        for submodel in submodels:\n",
        "          preds.append(submodel.predict(input_img.reshape(1,28,28,1)))\n",
        "        i = image_grid([input_img], [-1], 1, 1)\n",
        "        i = plot_to_image(i)\n",
        "        with file_writer_img.as_default():\n",
        "          tf.summary.image(\"Input\", i, step=0)\n",
        "        for p in range(len(preds)):\n",
        "          imgs = [preds[p][0, :, :, k] for k in range(preds[p].shape[3])]\n",
        "          y = np.ones((preds[p].shape[3],), dtype=int)*(-1)\n",
        "          i = image_grid(imgs, y, preds[p].shape[3], int(np.sqrt(preds[p].shape[3])))\n",
        "          i = plot_to_image(i)\n",
        "          with file_writer_img.as_default():\n",
        "            tf.summary.image(f\"Conv layer {p+1} output\", i, step=epoch)\n",
        "    \n",
        "    return log_intermediate_images"
      ],
      "metadata": {
        "id": "95s0U5boKnZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_log_kernels(weights_list: list, file_writer_kernel: tf.summary.SummaryWriter):\n",
        "    \"\"\"\n",
        "    Create a callback that will plot a confusion matrix\n",
        "\n",
        "    Args:\n",
        "        weights_list(list): a list of layers' weights\n",
        "        file_writer_kernel (tf.summary.SummaryWriter): a file writer\n",
        "    \"\"\"\n",
        "\n",
        "    def log_kernels(epoch: int, logs: dict):\n",
        "        \"\"\"\n",
        "        Log kernels\n",
        "        Args:\n",
        "            epoch (int): current epoch\n",
        "            logs (dict): logs\n",
        "        \"\"\"\n",
        "        for w, weights in enumerate(weights_list):\n",
        "          weights = np.asanyarray(weights)\n",
        "          imgs = [weights[:, :, 0, k] for k in range(weights.shape[3])]\n",
        "          y = np.ones((weights.shape[3],), dtype=int)*(-1)\n",
        "          i = image_grid(imgs, y, weights.shape[3], int(np.sqrt(weights.shape[3])))\n",
        "          i = plot_to_image(i)\n",
        "          with file_writer_kernel.as_default():\n",
        "            tf.summary.image(f\"Kernel layer {w+1} output\", i, step=epoch)\n",
        "    \n",
        "    return log_kernels"
      ],
      "metadata": {
        "id": "K_H03WHOkaNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(x_train: np.ndarray,\n",
        "                y_train: np.ndarray,\n",
        "                x_test: np.ndarray,\n",
        "                y_test: np.ndarray,\n",
        "                log_folder: str = None,\n",
        "                epochs: int = 5):\n",
        "  \"\"\"\n",
        "  Train a simple sequential model\n",
        "  \n",
        "  Args:\n",
        "      x_train (np.ndarray): training data\n",
        "      y_train (np.ndarray): training labels\n",
        "      x_test (np.ndarray): test data\n",
        "      y_test (np.ndarray): test labels\n",
        "      log_folder (str, optional): directory to save logs. Defaults to './logs/'.\n",
        "      epochs (int, optional): number of epochs to train. Defaults to 5. \n",
        "  \"\"\"\n",
        "  # Create and train the model\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Define log dir\n",
        "  if log_folder == None:\n",
        "    logdir = os.path.join('logs', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  else:\n",
        "    logdir = log_folder\n",
        "\n",
        "  # Create file writer\n",
        "  file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "  # Create submodels\n",
        "  submodels = []\n",
        "  submodels.append(tf.keras.models.Model(inputs=[model.get_layer('conv1').input], outputs=[model.get_layer('conv1').output]))\n",
        "  submodels.append(tf.keras.models.Model(inputs=[model.get_layer('conv1').input], outputs=[model.get_layer('conv2').output]))\n",
        "  submodels.append(tf.keras.models.Model(inputs=[model.get_layer('conv1').input], outputs=[model.get_layer('conv3').output]))\n",
        "\n",
        "  # Create weights list\n",
        "  weights_list = []\n",
        "  weights_list.append(model.get_layer('conv1').weights[0])\n",
        "  weights_list.append(model.get_layer('conv2').weights[0])\n",
        "  weights_list.append(model.get_layer('conv3').weights[0])\n",
        "\n",
        "  # Create callbacks list\n",
        "  callbacks = [tf.keras.callbacks.TensorBoard(logdir, \n",
        "                                              histogram_freq=1, \n",
        "                                              profile_batch='250,500'),\n",
        "               tf.keras.callbacks.LambdaCallback(on_epoch_end=create_log_images(submodels,\n",
        "                                                                                x_test[0],\n",
        "                                                                                file_writer)),\n",
        "               tf.keras.callbacks.LambdaCallback(on_epoch_end=create_log_kernels(weights_list,\n",
        "                                                                                 file_writer))]\n",
        "\n",
        "  # Train the model\n",
        "  model.fit(x=x_train, \n",
        "            y=y_train, \n",
        "            epochs=epochs, \n",
        "            validation_data=(x_test, y_test), \n",
        "            callbacks=callbacks)\n",
        "  return model, submodels"
      ],
      "metadata": {
        "id": "aqzAxwEk27Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "AolhTl3WhLqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=logs"
      ],
      "metadata": {
        "id": "XpfVQI9V4fLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, submodels = train_model(x_train_scaled, y_train, x_test_scaled, y_test, epochs=5)"
      ],
      "metadata": {
        "id": "L71ellzW3DZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "V0sWhov81nIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GE7mxKYChNIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I9JTZJmsm5fo"
      }
    }
  ]
}